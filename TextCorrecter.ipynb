{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import nltk\n",
    "\n",
    "from correct_text import train, decode, decode_sentence, evaluate_accuracy, create_model,\\\n",
    "    DefaultPTBConfig, DefaultMovieDialogConfig\n",
    "from text_correcter_data_readers import PTBDataReader, MovieDialogReader\n",
    "from text_correcter_models import InputBiasedLanguageModel\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "root_data_path = \"/Users/atpaino/data/textcorrecter/dialog_corpus\"\n",
    "train_path = os.path.join(root_data_path, \"cleaned_dialog_train.txt\")\n",
    "val_path = os.path.join(root_data_path, \"cleaned_dialog_val.txt\")\n",
    "test_path = os.path.join(root_data_path, \"cleaned_dialog_test.txt\")\n",
    "model_path = os.path.join(root_data_path, \"dialog_correcter_model\")\n",
    "config = DefaultMovieDialogConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_reader = MovieDialogReader(config, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train(data_reader, train_path, val_path, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_reader = MovieDialogReader(config, train_path, dropout_prob=0.25, replacement_prob=0.25, dataset_copies=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngram_model = InputBiasedLanguageModel(data_reader, train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800534625413185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_model.prob(\"hello\", [], [\"hello\", \"friend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3200131397951014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_model.prob(\"friend\", [], [\"hello\", \"friend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_model.prob(\"friend\", [\"hello\"], [\"hello\", \"friend\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from /Users/atpaino/data/textcorrecter/dialog_corpus/dialog_correcter_model/translate.ckpt-15000\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "model = create_model(sess, True, model_path, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adj prob of them is 7.26981852495e-08, orig prob is 7.26981852495e-08\n",
      "adj prob of a is 1.00000099258, orig prob is 9.92584318737e-07\n",
      "adj prob of some is 3.25696510117e-06, orig prob is 3.25696510117e-06\n",
      "adj prob of the is 1.00000054286, orig prob is 5.42858572317e-07\n",
      "adj prob of we is 2.07565299206e-05, orig prob is 2.07565299206e-05\n",
      "adj prob of i is 1.17047693493e-05, orig prob is 1.17047693493e-05\n",
      "adj prob of you is 1.99985921383, orig prob is 0.999859213829\n",
      "adj prob of they is 0.000102192170743, orig prob is 0.000102192170743\n",
      "adj prob of those is 1.33790749146e-07, orig prob is 1.33790749146e-07\n",
      "adj prob of have is 1.00000088826, orig prob is 8.8825555622e-07\n",
      "Using token you\n",
      "adj prob of kept is 1.59370938491e-06, orig prob is 1.59370938491e-06\n",
      "adj prob of be is 1.62224534961e-06, orig prob is 1.62224534961e-06\n",
      "adj prob of 'll is 1.09729231894, orig prob is 0.0972923189402\n",
      "adj prob of got is 3.11434405376e-06, orig prob is 3.11434405376e-06\n",
      "adj prob of some is 2.86392605631e-06, orig prob is 2.86392605631e-06\n",
      "adj prob of 've is 1.00152316887, orig prob is 0.00152316887397\n",
      "adj prob of have is 1.90114182234, orig prob is 0.901141822338\n",
      "adj prob of need is 3.14479257213e-06, orig prob is 3.14479257213e-06\n",
      "adj prob of met is 1.77927518052e-06, orig prob is 1.77927518052e-06\n",
      "adj prob of a is 1.00001390304, orig prob is 1.39030398714e-05\n",
      "Using token have\n",
      "adj prob of being is 0.000527829513885, orig prob is 0.000527829513885\n",
      "adj prob of england is 0.000671518326271, orig prob is 0.000671518326271\n",
      "adj prob of girlfriend is 1.00154296542, orig prob is 0.00154296541587\n",
      "adj prob of an is 1.01235557813, orig prob is 0.012355578132\n",
      "adj prob of a is 1.94040936232, orig prob is 0.940409362316\n",
      "adj prob of war is 0.00163151277229, orig prob is 0.00163151277229\n",
      "adj prob of ball is 0.0014210222289, orig prob is 0.0014210222289\n",
      "adj prob of the is 1.02032721974, orig prob is 0.0203272197396\n",
      "adj prob of heart is 0.00182232086081, orig prob is 0.00182232086081\n",
      "adj prob of some is 0.00480242632329, orig prob is 0.00480242632329\n",
      "Using token a\n",
      "adj prob of computer is 0.0119275078177, orig prob is 0.0119275078177\n",
      "adj prob of good is 0.012416575104, orig prob is 0.012416575104\n",
      "adj prob of day is 0.0126476343721, orig prob is 0.0126476343721\n",
      "adj prob of family is 0.0157193224877, orig prob is 0.0157193224877\n",
      "adj prob of most is 0.0163737796247, orig prob is 0.0163737796247\n",
      "adj prob of first is 0.0166769269854, orig prob is 0.0166769269854\n",
      "adj prob of war is 0.0402464568615, orig prob is 0.0402464568615\n",
      "adj prob of ball is 0.0549845211208, orig prob is 0.0549845211208\n",
      "adj prob of girlfriend is 1.14335468411, orig prob is 0.143354684114\n",
      "adj prob of heart is 0.3597638309, orig prob is 0.3597638309\n",
      "Using token girlfriend\n",
      "Input: you have girlfriend\n",
      "Output: you have a girlfriend\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test a sample from the test dataset.\n",
    "decoded = decode_sentence(sess, model, data_reader, \"you have girlfriend\", ngram_model=ngram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kvothe', 'went', 'to', 'the', 'market']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(sess, model, data_reader, \"kvothe went to market\", ngram_model=ngram_model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blablahblah', 'and', 'bladdddd', 'went', 'to', 'the', 'market']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(sess, model, data_reader, \"blablahblah and bladdddd went to market\", ngram_model=ngram_model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: do you have book\n",
      "Output: do you have a book\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decode_sentence(sess, model, data_reader, \"do you have book\", ngram_model=ngram_model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she', 'did', 'better', 'then', 'him']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sentence(sess, model, data_reader, \"she did better then him\", ngram_model=ngram_model, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket 0: (10, 10)\n",
      "\tBaseline BLEU = 0.8165\n",
      "\tModel BLEU = 0.6651\n",
      "\tBaseline Accuracy: 0.8959\n",
      "\tModel Accuracy: 0.6876\n",
      "Bucket 1: (15, 15)\n",
      "\tBaseline BLEU = 0.8647\n",
      "\tModel BLEU = 0.7013\n",
      "\tBaseline Accuracy: 0.7561\n",
      "\tModel Accuracy: 0.3780\n",
      "Bucket 2: (20, 20)\n",
      "\tBaseline BLEU = 0.8951\n",
      "\tModel BLEU = 0.7148\n",
      "\tBaseline Accuracy: 0.7736\n",
      "\tModel Accuracy: 0.3679\n",
      "Bucket 3: (40, 40)\n",
      "\tBaseline BLEU = 0.9072\n",
      "\tModel BLEU = 0.7216\n",
      "\tBaseline Accuracy: 0.5397\n",
      "\tModel Accuracy: 0.1111\n"
     ]
    }
   ],
   "source": [
    "evaluate_accuracy(sess, model, data_reader, test_path, max_samples=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
